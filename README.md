# An√°lisis de Sentimientos en Rese√±as de Pel√≠culas

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![scikit-learn](https://img.shields.io/badge/scikit--learn-1.3.0-orange.svg)](https://scikit-learn.org/)
[![spaCy](https://img.shields.io/badge/spaCy-3.7.2-09a3d5.svg)](https://spacy.io/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

Proyecto de clasificaci√≥n binaria de sentimientos (positivo/negativo) en rese√±as de pel√≠culas del dataset IMDB. Implementa y compara dos arquitecturas: una cl√°sica basada en TF-IDF y otra basada en embeddings sem√°nticos pre-entrenados.

## üìã Tabla de Contenidos

- [Descripci√≥n del Proyecto](#-descripci√≥n-del-proyecto)
- [Arquitecturas Implementadas](#-arquitecturas-implementadas)
- [Resultados](#-resultados)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Instalaci√≥n](#-instalaci√≥n)
- [Uso](#-uso)
- [Metodolog√≠a](#-metodolog√≠a)
- [An√°lisis de Resultados](#-an√°lisis-de-resultados)
- [Limitaciones](#-limitaciones)
- [Pr√≥ximos Pasos](#-pr√≥ximos-pasos)
- [Referencias](#-referencias)

## üéØ Descripci√≥n del Proyecto

Este proyecto desarrolla y eval√∫a dos enfoques diferentes para clasificaci√≥n de sentimientos en texto:

1. **Enfoque cl√°sico**: TF-IDF + Logistic Regression
2. **Enfoque basado en embeddings**: tok2vec (spaCy) + Linear SVM

El objetivo es comparar ambas metodolog√≠as en t√©rminos de rendimiento, interpretabilidad y eficiencia computacional, demostrando competencias en:
- Preprocesamiento de texto con spaCy
- Feature engineering (TF-IDF, embeddings)
- Evaluaci√≥n rigurosa de modelos
- An√°lisis de errores e interpretabilidad

## üèóÔ∏è Arquitecturas Implementadas

### Arquitectura 1: TF-IDF + Logistic Regression

**Pipeline:**
```
Texto ‚Üí Preprocesamiento spaCy ‚Üí TF-IDF Vectorization ‚Üí Logistic Regression ‚Üí Predicci√≥n
```

**Caracter√≠sticas:**
- **Vectorizaci√≥n**: TF-IDF con 5,000 features m√°ximas, unigramas y bigramas
- **Clasificador**: Logistic Regression con regularizaci√≥n L2 (C=1.0)
- **Ventajas**: Alta interpretabilidad, r√°pido entrenamiento, bajo uso de memoria
- **Desventajas**: No captura similitud sem√°ntica entre palabras

### Arquitectura 2: tok2vec + Linear SVM

**Pipeline:**
```
Texto ‚Üí Preprocesamiento spaCy ‚Üí tok2vec Embeddings ‚Üí Linear SVM ‚Üí Predicci√≥n
```

**Caracter√≠sticas:**
- **Vectorizaci√≥n**: Embeddings pre-entrenados de spaCy `en_core_web_lg` (300 dims)
- **Clasificador**: Linear SVM con kernel lineal (C=1.0)
- **Ventajas**: Captura relaciones sem√°nticas, vectores densos pre-entrenados
- **Desventajas**: Menos interpretable, mayor costo computacional

## üìä Resultados

### M√©tricas de Evaluaci√≥n

| Modelo | Accuracy | Precision | Recall | F1-Score | AUC-ROC |
|--------|----------|-----------|--------|----------|---------|
| **LR + TF-IDF** | 0.8750 | 0.8842 | 0.8640 | 0.8740 | 0.9445 |
| **SVM + tok2vec** | 0.8590 | 0.8452 | 0.8800 | 0.8623 | 0.9312 |
| **Baseline (mayor√≠a)** | 0.5000 | - | - | - | 0.5000 |

**Observaciones clave:**
- Ambos modelos superan significativamente el baseline
- **TF-IDF + LR** obtiene mejor F1-Score general (0.8740 vs 0.8623)
- **tok2vec + SVM** tiene mejor recall (0.8800 vs 0.8640) ‚Üí detecta m√°s casos positivos
- Validaci√≥n cruzada 5-fold confirma estabilidad de los modelos

### Visualizaciones

<p align="center">
  <img src="results/04_confusion_matrices.png" width="800" alt="Matrices de Confusi√≥n">
</p>

<p align="center">
  <img src="results/05_roc_curves.png" width="600" alt="Curvas ROC">
</p>

<p align="center">
  <img src="results/08_feature_importance.png" width="800" alt="Features Importantes">
</p>

## üìÅ Estructura del Proyecto

```
sentiment-analysis-nlp/
‚îÇ
‚îú‚îÄ‚îÄ README.md                          # Este archivo
‚îú‚îÄ‚îÄ requirements.txt                   # Dependencias del proyecto
‚îú‚îÄ‚îÄ sentiment_analysis_improved.ipynb  # Notebook principal con an√°lisis completo
‚îú‚îÄ‚îÄ movie_reviews_dataset_5000.csv     # Dataset de rese√±as (no incluido en repo)
‚îÇ
‚îú‚îÄ‚îÄ models/                            # Modelos entrenados (generados al ejecutar)
‚îÇ   ‚îú‚îÄ‚îÄ lr_tfidf_sentiment.pkl
‚îÇ   ‚îú‚îÄ‚îÄ svm_tok2vec_sentiment.pkl
‚îÇ   ‚îú‚îÄ‚îÄ tfidf_vectorizer.pkl
‚îÇ   ‚îî‚îÄ‚îÄ spacy_model_info.txt
‚îÇ
‚îú‚îÄ‚îÄ results/                           # Visualizaciones y m√©tricas (generadas al ejecutar)
‚îÇ   ‚îú‚îÄ‚îÄ model_metrics.csv
‚îÇ   ‚îú‚îÄ‚îÄ 01_sentiment_distribution.png
‚îÇ   ‚îú‚îÄ‚îÄ 02_length_distribution.png
‚îÇ   ‚îú‚îÄ‚îÄ 03_top_words_raw.png
‚îÇ   ‚îú‚îÄ‚îÄ 04_confusion_matrices.png
‚îÇ   ‚îú‚îÄ‚îÄ 05_roc_curves.png
‚îÇ   ‚îú‚îÄ‚îÄ 06_metrics_comparison.png
‚îÇ   ‚îú‚îÄ‚îÄ 07_confidence_analysis.png
‚îÇ   ‚îú‚îÄ‚îÄ 08_feature_importance.png
‚îÇ   ‚îî‚îÄ‚îÄ 09_learning_curves.png
‚îÇ
‚îî‚îÄ‚îÄ .gitignore                         # Archivos ignorados por Git
```

## üöÄ Instalaci√≥n

### Requisitos Previos
- Python 3.8 o superior
- pip para gesti√≥n de paquetes

### Pasos de Instalaci√≥n

1. **Clonar el repositorio**
```bash
git clone https://github.com/tu-usuario/sentiment-analysis-nlp.git
cd sentiment-analysis-nlp
```

2. **Crear entorno virtual (recomendado)**
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Descargar modelo de spaCy**
```bash
python -m spacy download en_core_web_lg
```

## üíª Uso

### Opci√≥n 1: Google Colab (Recomendado)

1. Abre el notebook en Google Colab
2. Sube el archivo `movie_reviews_dataset_5000.csv` cuando se te solicite
3. Ejecuta las celdas secuencialmente

### Opci√≥n 2: Jupyter Notebook Local

```bash
jupyter notebook sentiment_analysis_improved.ipynb
```

### Opci√≥n 3: Usar Modelos Pre-entrenados

```python
import joblib
import spacy

# Cargar modelos guardados
lr_model = joblib.load('models/lr_tfidf_sentiment.pkl')
tfidf = joblib.load('models/tfidf_vectorizer.pkl')
nlp = spacy.load('en_core_web_lg')

# Funci√≥n de preprocesamiento (copiar del notebook)
def preprocess_text(text):
    # ... c√≥digo de preprocesamiento
    pass

# Predecir sentimiento
new_review = "This movie was absolutely fantastic!"
clean_text = preprocess_text(new_review)
text_tfidf = tfidf.transform([clean_text])
prediction = lr_model.predict(text_tfidf)[0]
probability = lr_model.predict_proba(text_tfidf)[0]

print(f"Sentimiento: {'Positivo' if prediction == 1 else 'Negativo'}")
print(f"Confianza: {probability[prediction]*100:.2f}%")
```

## üî¨ Metodolog√≠a

### 1. Preprocesamiento de Texto

Pipeline de preprocesamiento con spaCy (`en_core_web_lg`):

1. **Limpieza**: Eliminaci√≥n de HTML tags, URLs, caracteres especiales
2. **Normalizaci√≥n**: Conversi√≥n a min√∫sculas
3. **Lematizaci√≥n**: Reducci√≥n de palabras a su forma base (e.g., "running" ‚Üí "run")
4. **Filtrado de stopwords**: Eliminaci√≥n de palabras comunes excepto **negaciones** (not, never, no)
5. **Filtrado de tokens**: Solo tokens alfab√©ticos de >1 car√°cter

**Decisi√≥n cr√≠tica**: Preservar negaciones porque son esenciales para an√°lisis de sentimientos
- Ejemplo: "not good" tiene significado opuesto a "good"

### 2. Feature Engineering

#### TF-IDF (Term Frequency-Inverse Document Frequency)

- **max_features=5000**: Vocabulario limitado a 5,000 t√©rminos m√°s frecuentes
- **ngram_range=(1,2)**: Unigramas y bigramas para capturar frases
- **min_df=2**: Ignora t√©rminos que aparecen en <2 documentos
- **sublinear_tf=True**: Aplica escala logar√≠tmica a frecuencias

#### tok2vec Embeddings

- **Modelo**: spaCy `en_core_web_lg` (300 dimensiones)
- **Estrategia**: Promedio de vectores de todos los tokens del documento
- **Ventaja**: Captura similitud sem√°ntica pre-aprendida en corpus masivo

### 3. Evaluaci√≥n

**Estrategia de validaci√≥n:**
- Train/Test split: 80/20 estratificado
- Validaci√≥n cruzada: 5-fold StratifiedKFold
- M√©tricas: Accuracy, Precision, Recall, F1-Score, AUC-ROC

**An√°lisis realizado:**
- Matrices de confusi√≥n (conteos y porcentajes)
- Curvas ROC y AUC
- An√°lisis de errores (falsos positivos y falsos negativos)
- An√°lisis de confianza en predicciones
- Features m√°s discriminativas (TF-IDF)
- Curvas de aprendizaje

## üìà An√°lisis de Resultados

### Comparaci√≥n de Arquitecturas

**TF-IDF + Logistic Regression:**
- ‚úÖ **Mejor F1-Score general** (0.8740)
- ‚úÖ **Alta interpretabilidad**: Podemos ver qu√© palabras influyen m√°s
- ‚úÖ **R√°pido**: Entrenamiento e inferencia muy eficientes
- ‚úÖ **Bajo uso de memoria**: Matrices sparse
- ‚ùå No captura similitud sem√°ntica ("excellent" y "great" son palabras independientes)

**tok2vec + Linear SVM:**
- ‚úÖ **Mejor recall** (0.8800): Detecta m√°s casos positivos
- ‚úÖ **Representaci√≥n sem√°ntica**: Palabras similares tienen vectores similares
- ‚úÖ **Pre-entrenado**: Aprovecha conocimiento de corpus masivo
- ‚ùå Menor interpretabilidad
- ‚ùå Mayor costo computacional
- ‚ùå Requiere m√°s memoria (vectores densos)

### Features M√°s Importantes (TF-IDF)

**Top t√©rminos que indican sentimiento POSITIVO:**
- excellent, perfect, wonderful, brilliant, outstanding
- best, great, amazing, loved, masterpiece

**Top t√©rminos que indican sentimiento NEGATIVO:**
- waste, awful, boring, terrible, worst
- bad, poor, disappoint, dull, stupid

**Observaci√≥n**: El modelo captura correctamente palabras con fuerte carga emocional.

### An√°lisis de Errores

**Casos dif√≠ciles para ambos modelos:**
- Rese√±as con sentimientos mixtos: "Acting was good but plot was boring"
- Sarcasmo e iron√≠a: "Oh great, another terrible sequel"
- Rese√±as neutrales: "Not great, not terrible, just average"
- Sentimientos contextuales que requieren comprensi√≥n profunda

**Patr√≥n identificado**: El modelo tiene menor confianza en predicciones err√≥neas vs correctas, indicando que "sabe cuando no sabe".

## ‚ö†Ô∏è Limitaciones

1. **Dataset balanceado**: 50/50 positivo/negativo. Performance en datos reales desbalanceados puede variar.

2. **Clasificaci√≥n binaria**: No captura intensidad (muy positivo vs ligeramente positivo) ni neutralidad.

3. **Dominio espec√≠fico**: Entrenado en rese√±as de pel√≠culas. Rendimiento en otros dominios (productos, restaurantes) requiere validaci√≥n.

4. **Contexto limitado**: No maneja efectivamente sarcasmo, iron√≠a o referencias culturales complejas.

5. **Embeddings est√°ticos**: tok2vec no es contextual (vs BERT que genera embeddings dependientes del contexto).

## üöÄ Pr√≥ximos Pasos

### Mejoras de Corto Plazo

1. **Modelos basados en Transformers**: Fine-tuning de BERT, RoBERTa o DistilBERT
2. **Ensemble de modelos**: Combinar TF-IDF + LR y tok2vec + SVM
3. **Optimizaci√≥n de hiperpar√°metros**: GridSearchCV o b√∫squeda bayesiana
4. **Evaluaci√≥n multi-dominio**: Testear en otros tipos de rese√±as

### Mejoras de Largo Plazo

1. **Clasificaci√≥n multi-clase**: Muy negativo, negativo, neutral, positivo, muy positivo
2. **Aspect-Based Sentiment Analysis**: Analizar sentimientos sobre aspectos espec√≠ficos
3. **Detecci√≥n de sarcasmo e iron√≠a**: Modelos especializados
4. **Pipeline de producci√≥n**: API REST, containerizaci√≥n, monitoreo

## üìö Referencias

### Dataset
- **IMDB Movie Reviews Dataset**: 5,000 rese√±as balanceadas de pel√≠culas

### Librer√≠as y Frameworks
- **scikit-learn**: Pedregosa et al. (2011). *Scikit-learn: Machine Learning in Python*
- **spaCy**: Honnibal & Montani (2017). *spaCy 2: Natural language understanding with Bloom embeddings*

### Papers Relevantes
- Maas et al. (2011). *Learning Word Vectors for Sentiment Analysis*. ACL.
- Devlin et al. (2018). *BERT: Pre-training of Deep Bidirectional Transformers*. NAACL.
- Pang & Lee (2008). *Opinion Mining and Sentiment Analysis*. Foundations and Trends in Information Retrieval.

---

‚≠ê Si este proyecto te fue √∫til, considera darle una estrella en GitHub
